{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9136850,
          "sourceType": "datasetVersion",
          "datasetId": 5398409
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Necessary Dependencies"
      ],
      "metadata": {
        "id": "xNQoZpaAcI_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl transformers accelerate git+https://github.com/huggingface/peft.git -Uqqq\n",
        "!pip install datasets sentence_transformers bitsandbytes einops wandb -Uqqq"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-08-10T09:55:43.717413Z",
          "iopub.execute_input": "2024-08-10T09:55:43.717845Z",
          "iopub.status.idle": "2024-08-10T09:56:57.386494Z",
          "shell.execute_reply.started": "2024-08-10T09:55:43.717809Z",
          "shell.execute_reply": "2024-08-10T09:56:57.385441Z"
        },
        "trusted": true,
        "id": "lAGWUo8Ejjwn",
        "outputId": "fcae2a27-089c-4768-9003-d1e0bf0be804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.7/316.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.8/313.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Necessary Libraries"
      ],
      "metadata": {
        "id": "0npDrgCoNsvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, GenerationConfig\n",
        "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:57:06.071544Z",
          "iopub.execute_input": "2024-08-10T09:57:06.071899Z",
          "iopub.status.idle": "2024-08-10T09:57:23.443534Z",
          "shell.execute_reply.started": "2024-08-10T09:57:06.071870Z",
          "shell.execute_reply": "2024-08-10T09:57:23.442611Z"
        },
        "trusted": true,
        "id": "gW_Jv8RCjjwp",
        "outputId": "a6ab568e-eae0-44f3-ac3a-7278b8b632e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-08-10 09:57:13.602935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-10 09:57:13.603042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-10 09:57:13.741708: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:57:23.445468Z",
          "iopub.execute_input": "2024-08-10T09:57:23.446288Z",
          "iopub.status.idle": "2024-08-10T09:57:23.476430Z",
          "shell.execute_reply.started": "2024-08-10T09:57:23.446248Z",
          "shell.execute_reply": "2024-08-10T09:57:23.475226Z"
        },
        "trusted": true,
        "id": "8d91yNYKjjwq",
        "outputId": "a9f9ac5c-3fd8-4c2e-c6b0-b400fea2477a",
        "colab": {
          "referenced_widgets": [
            "a0081c8276d1436ab594d2692dd23312"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0081c8276d1436ab594d2692dd23312"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "BRSyJObPNwEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/kaggle/input/dataset-to-use/dataset.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:57:36.556020Z",
          "iopub.execute_input": "2024-08-10T09:57:36.556386Z",
          "iopub.status.idle": "2024-08-10T09:57:36.598262Z",
          "shell.execute_reply.started": "2024-08-10T09:57:36.556357Z",
          "shell.execute_reply": "2024-08-10T09:57:36.597352Z"
        },
        "trusted": true,
        "id": "tIzpxi6yjjwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adding some guardrails"
      ],
      "metadata": {
        "id": "sAcguYbqNyep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "queries = [\n",
        "    \"Can you suggest any medication for anxiety?\",\n",
        "    \"What medicine should I take for stress relief?\",\n",
        "    \"Can you prescribe something for my mental health issues?\",\n",
        "    \"What are the best medications for anxiety?\",\n",
        "    \"Is there any over-the-counter medicine for stress?\",\n",
        "    \"Can you recommend a drug for anxiety?\",\n",
        "    \"Which medicine works best for anxiety?\",\n",
        "    \"I need medication for stress. What do you suggest?\",\n",
        "    \"Can you give me advice on medicine for mental health?\",\n",
        "    \"What should I take for stress and anxiety?\",\n",
        "    \"Is there a pill for anxiety you can recommend?\",\n",
        "    \"What medication can I use for stress?\",\n",
        "    \"I’m looking for something to help with anxiety. Any suggestions?\",\n",
        "    \"Do you know any effective medication for mental health problems?\",\n",
        "    \"What drugs are good for stress relief?\",\n",
        "    \"Can you tell me what to take for anxiety?\",\n",
        "    \"Which medication can help with my anxiety?\",\n",
        "    \"Can you recommend something for anxiety?\",\n",
        "    \"What should I take for my mental health issues?\",\n",
        "    \"Is there a specific medicine for stress?\",\n",
        "    \"What prescription should I ask for to manage my anxiety?\",\n",
        "    \"Can you tell me which drug helps with stress?\",\n",
        "    \"I’m struggling with anxiety. What medicine can help?\",\n",
        "    \"Is there a specific medication you recommend for stress?\",\n",
        "    \"Can you provide a name of a medicine for anxiety?\",\n",
        "    \"What’s a good medicine for anxiety that I can take?\",\n",
        "    \"Do you have any suggestions for medication to treat stress?\",\n",
        "    \"What are the options for anxiety medication?\",\n",
        "    \"Is there an anti-anxiety drug you can suggest?\",\n",
        "    \"Can you help me find a medication for stress?\",\n",
        "    \"What medicine should I consider for anxiety?\",\n",
        "    \"Can you provide a prescription for my mental health?\",\n",
        "    \"I need something to calm my anxiety. Any suggestions?\",\n",
        "    \"What’s the best medication for stress management?\",\n",
        "    \"Is there a medicine you recommend for anxiety?\",\n",
        "    \"What can I take for stress and anxiety?\",\n",
        "    \"Do you know a good medication for anxiety relief?\",\n",
        "    \"Can you prescribe me something for mental health issues?\",\n",
        "    \"What is the best over-the-counter medicine for anxiety?\",\n",
        "    \"Can you suggest an anti-stress medication?\",\n",
        "    \"What medication should I take for anxiety relief?\",\n",
        "    \"Is there a drug you can suggest for anxiety?\",\n",
        "    \"What’s a good stress-relief medicine?\",\n",
        "    \"Can you recommend any anxiety medication?\",\n",
        "    \"Is there something I can take for stress?\",\n",
        "    \"What are the best medications for anxiety and stress?\",\n",
        "    \"Can you recommend a prescription for mental health?\",\n",
        "    \"What over-the-counter medicine is good for stress?\",\n",
        "    \"Can you suggest something for anxiety relief?\",\n",
        "    \"What’s the best medication to deal with stress?\",\n",
        "    \"Do you have a recommendation for anxiety medicine?\",\n",
        "    \"What can I take to reduce anxiety?\",\n",
        "    \"Can you suggest any medication to manage stress?\",\n",
        "    \"What medicine is effective for treating anxiety?\",\n",
        "    \"Can you recommend something to help with my anxiety?\",\n",
        "    \"What should I take for mental health?\",\n",
        "    \"Is there a specific medication for stress relief?\",\n",
        "    \"Can you help me with a prescription for anxiety?\",\n",
        "    \"What drugs can I use to manage stress?\",\n",
        "    \"What’s the best medicine for stress?\",\n",
        "    \"Can you prescribe me something for anxiety?\",\n",
        "    \"Do you know any medicine that works for anxiety?\",\n",
        "    \"Can you recommend a drug for stress relief?\",\n",
        "    \"What can I take to help with anxiety?\",\n",
        "    \"Is there a good medication for mental health?\",\n",
        "    \"Can you provide advice on anxiety medication?\",\n",
        "    \"What over-the-counter drug should I take for anxiety?\",\n",
        "    \"Can you tell me what medicine to take for stress?\",\n",
        "    \"What should I ask my doctor to prescribe for anxiety?\",\n",
        "    \"Can you recommend a mental health medication?\",\n",
        "    \"What is the best drug for stress?\",\n",
        "    \"Is there a medicine you can suggest for anxiety?\",\n",
        "    \"Can you recommend a treatment for anxiety?\",\n",
        "    \"What medication is best for stress relief?\",\n",
        "    \"Is there something you can suggest for mental health issues?\",\n",
        "    \"Can you give me advice on stress medication?\",\n",
        "    \"What prescription can help with anxiety?\",\n",
        "    \"Can you suggest something for stress management?\",\n",
        "    \"What’s the best treatment for anxiety?\",\n",
        "    \"Is there a drug that can help with stress?\",\n",
        "    \"Can you tell me what to take for anxiety?\",\n",
        "    \"What’s the most effective medication for stress?\",\n",
        "    \"Can you recommend a pill for anxiety?\",\n",
        "    \"What can I take for mental health issues?\",\n",
        "    \"Is there any medication you suggest for anxiety?\",\n",
        "    \"Can you suggest an anti-anxiety drug?\",\n",
        "    \"What should I use to manage stress?\",\n",
        "    \"Is there a medicine you recommend for anxiety relief?\",\n",
        "    \"What’s the best way to medicate stress?\",\n",
        "    \"Can you suggest something for mental health treatment?\",\n",
        "    \"What medication would help with anxiety?\",\n",
        "    \"Is there a drug that you recommend for stress relief?\",\n",
        "    \"Can you provide a prescription for stress?\",\n",
        "    \"What should I take to calm my anxiety?\",\n",
        "]\n",
        "\n",
        "# Standard answer\n",
        "answer = \"As an AI Language Model, I cannot recommend or suggest any kind of medicine to you. I'm just here to talk to you, so please kindly consult a professional therapist or doctor. Thank you.\"\n",
        "\n",
        "# Generate 100 samples\n",
        "samples = [f\"<HUMAN>: {random.choice(queries)} <ASSISTANT>: {answer}\" for _ in range(100)]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-08T23:42:38.709593Z",
          "iopub.execute_input": "2024-08-08T23:42:38.709994Z",
          "iopub.status.idle": "2024-08-08T23:42:38.722657Z",
          "shell.execute_reply.started": "2024-08-08T23:42:38.709967Z",
          "shell.execute_reply": "2024-08-08T23:42:38.721581Z"
        },
        "trusted": true,
        "id": "ECkYT8YSjjwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-08T23:21:16.326182Z",
          "iopub.execute_input": "2024-08-08T23:21:16.326545Z",
          "iopub.status.idle": "2024-08-08T23:21:16.332558Z",
          "shell.execute_reply.started": "2024-08-08T23:21:16.326515Z",
          "shell.execute_reply": "2024-08-08T23:21:16.331677Z"
        },
        "trusted": true,
        "id": "ea_X9DXzjjws",
        "outputId": "087f4849-9b5e-4bcf-b8c1-13f23ba6c833"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 78,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(1106, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding guadrails to existing dataset"
      ],
      "metadata": {
        "id": "V89XZCDAN51E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.DataFrame(samples, columns=['text'])\n",
        "\n",
        "# Append the new samples to the existing DataFrame\n",
        "df = pd.concat([df, new_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-08T23:22:16.169743Z",
          "iopub.execute_input": "2024-08-08T23:22:16.170597Z",
          "iopub.status.idle": "2024-08-08T23:22:16.178653Z",
          "shell.execute_reply.started": "2024-08-08T23:22:16.170560Z",
          "shell.execute_reply": "2024-08-08T23:22:16.177768Z"
        },
        "trusted": true,
        "id": "ZfV8ViuWjjws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:58:00.844229Z",
          "iopub.execute_input": "2024-08-10T09:58:00.844608Z",
          "iopub.status.idle": "2024-08-10T09:58:00.851362Z",
          "shell.execute_reply.started": "2024-08-10T09:58:00.844578Z",
          "shell.execute_reply": "2024-08-10T09:58:00.850370Z"
        },
        "trusted": true,
        "id": "MM289Q6vjjwt",
        "outputId": "1f957bbf-9bdd-4aec-facd-67e296834612"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(1206, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['text'].str.contains(\"<ASSISTANT>:\")].reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:58:06.351423Z",
          "iopub.execute_input": "2024-08-10T09:58:06.352342Z",
          "iopub.status.idle": "2024-08-10T09:58:06.364044Z",
          "shell.execute_reply.started": "2024-08-10T09:58:06.352299Z",
          "shell.execute_reply": "2024-08-10T09:58:06.363031Z"
        },
        "trusted": true,
        "id": "Smy0Cl9jjjwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reformatting dataset to Instruction Template for Mistral Model"
      ],
      "metadata": {
        "id": "9YP-sYUdOD2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a mental health assistant who always answer in very polite way. Answer the below user query in a helpful and friendly way. Don't repeat yourself and give complete response.\"\n",
        "\n",
        "# Function to reformat the dialogue\n",
        "def reformat_dialogue(row):\n",
        "    dialogue = row['text']\n",
        "    human_part = dialogue.split('<HUMAN>:')[1].split('<ASSISTANT>:')[0].strip()\n",
        "    assistant_part = dialogue.split('<ASSISTANT>:')[1].strip()\n",
        "\n",
        "    formatted_dialogue = f\"<s>[INST] <system>\\n{system_prompt}\\n<query>\\n{human_part} [/INST] <assistant>\\n{assistant_part}\"\n",
        "    return formatted_dialogue\n",
        "\n",
        "# Apply the reformatting function to each row\n",
        "df['text'] = df.apply(reformat_dialogue, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:58:07.297833Z",
          "iopub.execute_input": "2024-08-10T09:58:07.298207Z",
          "iopub.status.idle": "2024-08-10T09:58:07.323612Z",
          "shell.execute_reply.started": "2024-08-10T09:58:07.298171Z",
          "shell.execute_reply": "2024-08-10T09:58:07.322697Z"
        },
        "trusted": true,
        "id": "ys8cU4Jrjjwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:58:10.526184Z",
          "iopub.execute_input": "2024-08-10T09:58:10.527182Z",
          "iopub.status.idle": "2024-08-10T09:58:10.540330Z",
          "shell.execute_reply.started": "2024-08-10T09:58:10.527131Z",
          "shell.execute_reply": "2024-08-10T09:58:10.539225Z"
        },
        "trusted": true,
        "id": "H3KM7aCxjjwu",
        "outputId": "f78e7ab3-8b1d-4baf-8790-f65850c42667"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   text\n0     <s>[INST] <system>\\nYou are a mental health as...\n1     <s>[INST] <system>\\nYou are a mental health as...\n2     <s>[INST] <system>\\nYou are a mental health as...\n3     <s>[INST] <system>\\nYou are a mental health as...\n4     <s>[INST] <system>\\nYou are a mental health as...\n...                                                 ...\n1200  <s>[INST] <system>\\nYou are a mental health as...\n1201  <s>[INST] <system>\\nYou are a mental health as...\n1202  <s>[INST] <system>\\nYou are a mental health as...\n1203  <s>[INST] <system>\\nYou are a mental health as...\n1204  <s>[INST] <system>\\nYou are a mental health as...\n\n[1205 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1200</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>&lt;s&gt;[INST] &lt;system&gt;\\nYou are a mental health as...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1205 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:58:15.686115Z",
          "iopub.execute_input": "2024-08-10T09:58:15.686476Z",
          "iopub.status.idle": "2024-08-10T09:58:15.720890Z",
          "shell.execute_reply.started": "2024-08-10T09:58:15.686449Z",
          "shell.execute_reply": "2024-08-10T09:58:15.720115Z"
        },
        "trusted": true,
        "id": "2hlxC5QBjjwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:58:15.974176Z",
          "iopub.execute_input": "2024-08-10T09:58:15.974982Z",
          "iopub.status.idle": "2024-08-10T09:58:15.980428Z",
          "shell.execute_reply.started": "2024-08-10T09:58:15.974950Z",
          "shell.execute_reply": "2024-08-10T09:58:15.979482Z"
        },
        "trusted": true,
        "id": "-rOP2DDzjjwu",
        "outputId": "7fbb80b4-9911-4d8a-8fcc-5d3431af3456"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text'],\n    num_rows: 1205\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantizing the Mistral 7B Model to 4-bit"
      ],
      "metadata": {
        "id": "gVf08IxiON5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,            # load model in 4-bit precision\n",
        "    bnb_4bit_quant_type=\"nf4\",    # pre-trained model should be quantized in 4-bit NF format\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    llm_int8_has_fp16_weight= True\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:58:58.524972Z",
          "iopub.execute_input": "2024-08-10T09:58:58.525633Z",
          "iopub.status.idle": "2024-08-10T10:00:20.880141Z",
          "shell.execute_reply.started": "2024-08-10T09:58:58.525598Z",
          "shell.execute_reply": "2024-08-10T10:00:20.879358Z"
        },
        "trusted": true,
        "id": "lL-WKwIFjjwu",
        "outputId": "5a6fe2a9-8b02-4f93-d4b0-f01e02336d1a",
        "colab": {
          "referenced_widgets": [
            "ee7b73908b5540a6aa1ea6bf975d121d",
            "f42d90922b2244beb13283e3ef4c7c11",
            "8946c11f737846b7b00878fe1c821a58",
            "c964814b4c1943d382a570d8f33d2666",
            "e7fe7cb9e694488097c43e32af29e618",
            "23ce81e85b3a484a92b95e7b5164ac1d",
            "021cdec1199c46188f06785830c0c758",
            "17fbe82fd55949e68353f04529c02a9d",
            "ca62e2630a774051ae554a2a5dc1e593",
            "527753755b3c40d38a37625b5ef3c0b1",
            "8a6a3c2a032144d0958f4d56ed027f5d",
            "94e764983ccd480081df1912ab4fa773"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee7b73908b5540a6aa1ea6bf975d121d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f42d90922b2244beb13283e3ef4c7c11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8946c11f737846b7b00878fe1c821a58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c964814b4c1943d382a570d8f33d2666"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7fe7cb9e694488097c43e32af29e618"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23ce81e85b3a484a92b95e7b5164ac1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "021cdec1199c46188f06785830c0c758"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17fbe82fd55949e68353f04529c02a9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca62e2630a774051ae554a2a5dc1e593"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "527753755b3c40d38a37625b5ef3c0b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a6a3c2a032144d0958f4d56ed027f5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94e764983ccd480081df1912ab4fa773"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:00:27.008692Z",
          "iopub.execute_input": "2024-08-10T10:00:27.009460Z",
          "iopub.status.idle": "2024-08-10T10:00:27.013446Z",
          "shell.execute_reply.started": "2024-08-10T10:00:27.009428Z",
          "shell.execute_reply": "2024-08-10T10:00:27.012554Z"
        },
        "trusted": true,
        "id": "8HFCw1lvjjwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:00:27.222150Z",
          "iopub.execute_input": "2024-08-10T10:00:27.222800Z",
          "iopub.status.idle": "2024-08-10T10:00:27.231724Z",
          "shell.execute_reply.started": "2024-08-10T10:00:27.222770Z",
          "shell.execute_reply": "2024-08-10T10:00:27.230780Z"
        },
        "trusted": true,
        "id": "dbjRmOu0jjwu",
        "outputId": "3880c7bc-ef55-493c-e9a5-9fece719cd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32768, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n  )\n  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting LoRA Configuration for Paramter Efficient Fine Tuning"
      ],
      "metadata": {
        "id": "l31WULLXPKkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 64 # scaling factor for the weight matrices (2*rank seems reasonable in most cases)\n",
        "lora_dropout = 0.05\n",
        "lora_rank = 32 # dimension of the low-rank matrices\n",
        "\n",
        "# Set LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_rank,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "per_device_train_batch_size = 1 # reduce batch size by 2x if out-of-memory error\n",
        "gradient_accumulation_steps = 4  # increase gradient accumulation steps by 2x if batch size is reduced\n",
        "optim = \"paged_adamw_32bit\"\n",
        "save_strategy=\"steps\"\n",
        "save_steps = 30\n",
        "logging_steps = 10\n",
        "learning_rate = 2e-4\n",
        "max_grad_norm = 0.3\n",
        "max_steps = 120        # training will happen for 320 steps, could be 512, 1024. Depends on resources\n",
        "warmup_ratio = 0.03\n",
        "weight_decay = 0.001\n",
        "lr_scheduler_type = \"constant\"\n",
        "fp16 = True\n",
        "bf16 = False\n",
        "group_by_length = True\n",
        "packing = False\n",
        "output_dir = f\"./Mistral-7B-Instruct-v0.3-4bit-fp16-finetuned-mental-health-conversational_{max_steps}steps\"\n",
        "\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "#     num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps, # the total number of training steps to perform\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    push_to_hub=True\n",
        ")\n",
        "\n",
        "# Initialize the SFTTrainer for fine-tuning\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,  # You can specify the maximum sequence length here\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:00:56.211819Z",
          "iopub.execute_input": "2024-08-10T10:00:56.212491Z",
          "iopub.status.idle": "2024-08-10T10:00:58.954011Z",
          "shell.execute_reply.started": "2024-08-10T10:00:56.212459Z",
          "shell.execute_reply": "2024-08-10T10:00:58.953069Z"
        },
        "trusted": true,
        "id": "6i0LX2iejjwu",
        "outputId": "5360f90c-cd85-4dde-faa7-da088874187e",
        "colab": {
          "referenced_widgets": [
            "fbb8a9bbbc69460db74ab3ba629005b5"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1205 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbb8a9bbbc69460db74ab3ba629005b5"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "max_steps is given, it will override any value given in num_train_epochs\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:01:04.391137Z",
          "iopub.execute_input": "2024-08-10T10:01:04.391566Z",
          "iopub.status.idle": "2024-08-10T10:01:14.547456Z",
          "shell.execute_reply.started": "2024-08-10T10:01:04.391535Z",
          "shell.execute_reply": "2024-08-10T10:01:14.546503Z"
        },
        "trusted": true,
        "id": "q8gn7rg2jjwu",
        "outputId": "e3a7ce96-3e16-4862-af58-1a2ab55f20cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "model.config.use_cache = False\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "end = time.time()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:01:24.124537Z",
          "iopub.execute_input": "2024-08-10T10:01:24.125328Z",
          "iopub.status.idle": "2024-08-10T10:15:54.998763Z",
          "shell.execute_reply.started": "2024-08-10T10:01:24.125283Z",
          "shell.execute_reply": "2024-08-10T10:15:54.997775Z"
        },
        "trusted": true,
        "id": "V0mkb4ksjjwu",
        "outputId": "aec33cad-26d4-43e6-9824-0bae3dcb5cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayhoomsaloom\u001b[0m (\u001b[33mayhoomsaloom-university-of-birmingham\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240810_100125-xj2dxzwa</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ayhoomsaloom-university-of-birmingham/huggingface/runs/xj2dxzwa' target=\"_blank\">./Mistral-7B-Instruct-v0.3-4bit-fp16-finetuned-mental-health-conversational_120steps</a></strong> to <a href='https://wandb.ai/ayhoomsaloom-university-of-birmingham/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ayhoomsaloom-university-of-birmingham/huggingface' target=\"_blank\">https://wandb.ai/ayhoomsaloom-university-of-birmingham/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ayhoomsaloom-university-of-birmingham/huggingface/runs/xj2dxzwa' target=\"_blank\">https://wandb.ai/ayhoomsaloom-university-of-birmingham/huggingface/runs/xj2dxzwa</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [120/120 13:35, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.634000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.567600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.454000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.386000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.988800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.435200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.501600</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.481100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.345300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.616300</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.385400</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.463900</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It took 14.5 mints to fine tune the model on just 120 steps"
      ],
      "metadata": {
        "id": "p_vngFPJPXYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(end-start)/60"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:16:55.280386Z",
          "iopub.execute_input": "2024-08-10T10:16:55.281322Z",
          "iopub.status.idle": "2024-08-10T10:16:55.288937Z",
          "shell.execute_reply.started": "2024-08-10T10:16:55.281283Z",
          "shell.execute_reply": "2024-08-10T10:16:55.287898Z"
        },
        "trusted": true,
        "id": "k7yhBsmajjwv",
        "outputId": "700f3672-5754-48e0-bfc0-aa3691d8c1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "14.514478580156963"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:17:01.038346Z",
          "iopub.execute_input": "2024-08-10T10:17:01.039140Z",
          "iopub.status.idle": "2024-08-10T10:17:07.156785Z",
          "shell.execute_reply.started": "2024-08-10T10:17:01.039108Z",
          "shell.execute_reply": "2024-08-10T10:17:07.155813Z"
        },
        "trusted": true,
        "id": "eV4Y77nLjjwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference using Fine Tuned Model"
      ],
      "metadata": {
        "id": "IIUEJP_6QhIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def generate_responses(prompt, model, tokenizer):\n",
        "\n",
        "    peft_encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    peft_outputs = model.generate(input_ids=peft_encoding.input_ids, generation_config=GenerationConfig(max_new_tokens=256, pad_token_id = tokenizer.eos_token_id, \\\n",
        "                                                                                                                         eos_token_id = tokenizer.eos_token_id, attention_mask = peft_encoding.attention_mask, \\\n",
        "                                                                                                                         temperature=0.4, top_p=0.6, repetition_penalty=1.3, num_return_sequences=2, do_sample=True))\n",
        "    peft_text_output = tokenizer.decode(peft_outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    return peft_text_output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-08T23:59:35.937589Z",
          "iopub.execute_input": "2024-08-08T23:59:35.937958Z",
          "iopub.status.idle": "2024-08-08T23:59:35.946532Z",
          "shell.execute_reply.started": "2024-08-08T23:59:35.937928Z",
          "shell.execute_reply": "2024-08-08T23:59:35.945459Z"
        },
        "trusted": true,
        "id": "5QV5cZutjjwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "print(generate_responses(\"I am feeling so sad. I don't know why.\",trainer.model,trainer.tokenizer))\n",
        "end = time.time()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-09T00:02:20.598465Z",
          "iopub.execute_input": "2024-08-09T00:02:20.598835Z",
          "iopub.status.idle": "2024-08-09T00:03:06.380281Z",
          "shell.execute_reply.started": "2024-08-09T00:02:20.598799Z",
          "shell.execute_reply": "2024-08-09T00:03:06.379323Z"
        },
        "trusted": true,
        "id": "8M_cansLjjwv",
        "outputId": "be415ab1-c17b-497f-c96a-7027bf8b40a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<s> I am feeling so sad. I don't know why. [/INST] <system>\nI would suggest that you start by looking at what is going on in your life right now and how it may be contributing to the way you are feeling. It can also help if you try not to focus too much on yourself, but instead think about others or even animals. Sometimes we need a little distraction from our own lives. If this continues for an extended period of time then maybe consider seeing someone who specializes in mood disorders like depression.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(end-start)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-09T00:02:16.624459Z",
          "iopub.execute_input": "2024-08-09T00:02:16.624833Z",
          "iopub.status.idle": "2024-08-09T00:02:16.634883Z",
          "shell.execute_reply.started": "2024-08-09T00:02:16.624803Z",
          "shell.execute_reply": "2024-08-09T00:02:16.633871Z"
        },
        "trusted": true,
        "id": "QPgNSIcojjwv",
        "outputId": "76a93f72-3bc9-438d-e6f0-ed67c68366e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "67.4751033782959"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T10:17:28.040009Z",
          "iopub.execute_input": "2024-08-10T10:17:28.041246Z",
          "iopub.status.idle": "2024-08-10T10:17:28.068652Z",
          "shell.execute_reply.started": "2024-08-10T10:17:28.041196Z",
          "shell.execute_reply": "2024-08-10T10:17:28.067424Z"
        },
        "trusted": true,
        "id": "3r_FL58_jjwv",
        "outputId": "e57be661-040f-4c28-979a-cbb7a6fa6073"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32768, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n      (lm_head): lora.Linear(\n        (base_layer): Linear(in_features=4096, out_features=32768, bias=False)\n        (lora_dropout): ModuleDict(\n          (default): Dropout(p=0.05, inplace=False)\n        )\n        (lora_A): ModuleDict(\n          (default): Linear(in_features=4096, out_features=32, bias=False)\n        )\n        (lora_B): ModuleDict(\n          (default): Linear(in_features=32, out_features=32768, bias=False)\n        )\n        (lora_embedding_A): ParameterDict()\n        (lora_embedding_B): ParameterDict()\n        (lora_magnitude_vector): ModuleDict()\n      )\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZx4rxJhjjwx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}